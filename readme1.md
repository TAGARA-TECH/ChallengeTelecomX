Descripci√≥n del Notebook: Proceso ETL y EDA del Dataset Telecom X
Este notebook documenta las fases de Extracci√≥n, Transformaci√≥n y Carga (ETL) y An√°lisis Exploratorio de Datos (EDA) sobre un dataset de clientes de Telecom X, con el objetivo de identificar factores que influyen en la tasa de evasi√≥n (Churn).

Contenido por Celda
Celda 1: Inicializaci√≥n (Vac√≠a)
# Celda 1 (ipython-input-0-d7e97302a5e7)
# Inicializaci√≥n o celda vac√≠a.
pass # No hay c√≥digo para ejecutar
Usa el c√≥digo con precauci√≥n
Celda 2: Inicio de la Fase de Extracci√≥n
# üìå Extracci√≥n
Usa el c√≥digo con precauci√≥n
Celda 3: Carga Inicial de Datos
# Celda 3
# Importaci√≥n de librer√≠as y carga inicial de datos desde JSON.
import pandas as pd
import requests

# URL del archivo JSON crudo
url = 'https://raw.githubusercontent.com/TAGARA-TECH/ChallengeTelecomX/main/TelecomX_Data.json'

# Obtener los datos desde la "API"
response = requests.get(url)
data_json = response.json()

# Convertir a DataFrame
df = pd.DataFrame(data_json)

# Mostrar las primeras filas
df.head()
Usa el c√≥digo con precauci√≥n
Celda 4: Vista General del DataFrame
# Celda 4
# Vista general del DataFrame y tipos de datos.
print("Dimensiones del dataset:", df.shape)

# Columnas y tipos de datos
df.info()

# Tipos de datos por separado
print("\nTipos de datos:")
print(df.dtypes)

# Primeras filas para exploraci√≥n visual
df.head()
Usa el c√≥digo con precauci√≥n
Celda 5: Estad√≠sticas y Valores √önicos
# Celda 5
# Estad√≠sticas de variables num√©ricas y conteo de valores √∫nicos por columna.
# Estad√≠sticas de variables num√©ricas
df.describe()

# Ver valores √∫nicos por columna (para identificar categ√≥ricas)
print("\nVer valores √∫nicos por columna (para identificar categ√≥ricas):")
for col in df.columns:
    try:
        unique_vals = df[col].nunique()
        print(f"{col}: {unique_vals} valores √∫nicos")
    except TypeError as e:
        print(f"‚ö†Ô∏è Error en columna '{col}': {e}")
        print(f"üîç Primeros 2 valores no nulos en '{col}':")
        print(df[col].dropna().head(2).tolist())
Usa el c√≥digo con precauci√≥n
Celda 6: Comentario sobre Columnas Anidadas
el dataset tiene columnas anidadas, es decir, varias columnas contienen diccionarios dentro de cada fila. Para poder analizarlas correctamente en pandas, hay que "aplanarlas" (flatten), es decir, convertir esas claves internas en columnas separadas.
Usa el c√≥digo con precauci√≥n
Celda 7: Aplanamiento Manual (Primer Intento)
# Celda 7
# Expansi√≥n (aplanamiento) manual de las columnas anidadas: customer, phone, internet, account.
# Expandir la columna 'customer'
customer_df = df['customer'].apply(pd.Series)
df = df.drop('customer', axis=1).join(customer_df)

# Expandir la columna 'phone'
phone_df = df['phone'].apply(pd.Series)
df = df.drop('phone', axis=1).join(phone_df)

# Expandir la columna 'internet'
internet_df = df['internet'].apply(pd.Series)
df = df.drop('internet', axis=1).join(internet_df)

# Expandir la columna 'account'
account_df = df['account'].apply(pd.Series)

# Extraer tambi√©n los valores anidados en 'Charges'
charges_df = account_df['Charges'].apply(pd.Series)
account_df = account_df.drop('Charges', axis=1).join(charges_df)

# Unir todo al DataFrame original
df = df.drop('account', axis=1).join(account_df)
Usa el c√≥digo con precauci√≥n
Celda 8: Verificaci√≥n Despu√©s del Aplanamiento
# Celda 8
# Verificaci√≥n de la estructura y datos despu√©s del aplanamiento manual.
df.info()
df.head()
Usa el c√≥digo con precauci√≥n
Celda 9: Resumen del Estado y Pr√≥ximos Pasos
 Resumen del estado actual
üîπ Todas las columnas anidadas ya est√°n desglosadas correctamente.

üîπ customer_id est√° completamente vac√≠o (0 non-null), por lo tanto pod√©s eliminarla.

üîπ La columna Total est√° como object, aunque deber√≠a ser num√©rica (float), probablemente porque hay algunos valores mal formateados (por ejemplo, strings vac√≠os, espacios o caracteres no num√©ricos).

Pasos a seguir:
Eliminar customer_id.

Convertir Total a num√©rico (y ver qu√© errores aparecen si los hay).

Verificar si hay valores nulos tras esa conversi√≥n.
Usa el c√≥digo con precauci√≥n
Celda 10: Implementaci√≥n de Pasos de Limpieza
# Celda 10
# Implementaci√≥n de los primeros pasos de limpieza: eliminar customer_id y convertir Total a num√©rico.
# 1. Eliminar columna vac√≠a
df.drop(columns=['customer_id'], inplace=True)

# 2. Convertir 'Total' a num√©rico, forzando errores a NaN si hay problemas
df['Total'] = pd.to_numeric(df['Total'], errors='coerce')

# 3. Verificar si hubo valores nulos generados en 'Total'
print(f"Valores nulos en 'Total': {df['Total'].isna().sum()}")
Usa el c√≥digo con precauci√≥n
Celda 11: Estad√≠sticas Descriptivas (Incluye 'all')
# Celda 11
# Estad√≠sticas descriptivas incluyendo todas las columnas.
df.describe(include='all')
Usa el c√≥digo con precauci√≥n
Celda 12: Distribuci√≥n de Churn
# Celda 12
# Distribuci√≥n de la variable objetivo 'Churn'.
df['Churn'].value_counts(normalize=True)
Usa el c√≥digo con precauci√≥n
Celda 13: Conteo de Valores Nulos
# Celda 13
# Conteo de valores nulos en todas las columnas.
df.isna().sum()
Usa el c√≥digo con precauci√≥n
Celda 14: Visualizaci√≥n de Distribuci√≥n de Churn
# Celda 14
# Visualizaci√≥n de la distribuci√≥n de Churn.
import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=df, x='Churn')
plt.title("Distribuci√≥n de Churn")
plt.show()
Usa el c√≥digo con precauci√≥n
Celda 15: Celda Vac√≠a
# Celda 15 (Vac√≠a)
pass # No hay c√≥digo
Usa el c√≥digo con precauci√≥n
Celda 16: Verificaci√≥n de Problemas en los Datos
## **Verificar si hay problemas en los datos que puedan afectar el an√°lisis**
Esta etapa consiste en detectar y limpiar posibles problemas como:
Usa el c√≥digo con precauci√≥n
Celda 17: Valores Ausentes
# Celda 17
# 1. Valores ausentes (NaN o None)
df.isna().sum().sort_values(ascending=False)
Usa el c√≥digo con precauci√≥n
Celda 18: Porcentaje de Valores Faltantes
# Celda 18
# Porcentaje de valores faltantes.
(df.isna().sum() / len(df)).sort_values(ascending=False)
Usa el c√≥digo con precauci√≥n
Celda 19: Valores Duplicados
# Celda 19
# 2. Valores duplicados
df.duplicated().sum()
Usa el c√≥digo con precauci√≥n
Celda 20: Eliminaci√≥n de Duplicados
# Celda 20
# Si hay duplicados, pod√©s eliminarlos con:
df = df.drop_duplicates()
Usa el c√≥digo con precauci√≥n
Celda 21: Verificaci√≥n Post-Eliminaci√≥n de Duplicados
# Celda 21
# Verificaci√≥n despu√©s de eliminar duplicados.
print("Cantidad de filas duplicadas:", df.duplicated().sum())
Usa el c√≥digo con precauci√≥n
Celda 22: Errores de Formato (Strip)
# Celda 22
# 3. Errores de formato (eliminar espacios en blanco).
for col in df.select_dtypes(include='object'):
    df[col] = df[col].str.strip()
#Si hay columnas con fechas (parece que no en este dataset), ah√≠ se usar√≠a .dt.normalize() como menciona el tip.
Usa el c√≥digo con precauci√≥n
Celda 23: Inconsistencias en Categor√≠as (Valores √önicos)
# Celda 23
# 4. Inconsistencias en categor√≠as (listar valores √∫nicos).
for col in df.select_dtypes(include='object'):
    print(f"{col}: {df[col].unique()}")
Usa el c√≥digo con precauci√≥n
Celda 24: Tratamiento de Churn Vac√≠o
# Celda 24
# Tratamiento de Churn: reemplazar '' con NaN.
# Churn: ['No' 'Yes' '']
df['Churn'] = df['Churn'].replace('', np.nan)
Usa el c√≥digo con precauci√≥n
Celda 25: Tratamiento de MultipleLines Inconsistente
# Celda 25
# Tratamiento de MultipleLines: reemplazar 'No phone service' con 'No'.
# MultipleLines: ['No' 'Yes' 'No phone service']
df['MultipleLines'] = df['MultipleLines'].replace('No phone service', 'No')
Usa el c√≥digo con precauci√≥n
Celda 26: Tratamiento de Servicios Internet Inconsistentes
# Celda 26
# Tratamiento de columnas con 'No internet service':
 cols_internet = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
                 'TechSupport', 'StreamingTV', 'StreamingMovies']

for col in cols_internet:
    df[col] = df[col].replace('No internet service', 'No')
#Esta opci√≥n es muy com√∫n en an√°lisis predictivo.
Usa el c√≥digo con precauci√≥n
Celda 27: Comentario sobre Categor√≠as Limpias
Todo lo dem√°s:
'gender', 'Partner', 'Dependents', 'PhoneService', 'Contract', 'PaperlessBilling', 'PaymentMethod' ‚Üí No tienen inconsistencias, ¬°bien!
Usa el c√≥digo con precauci√≥n
Celda 28-30: Celdas Vac√≠as
# Celda 28, 29, 30 (Vac√≠as)
pass # No hay c√≥digo
Usa el c√≥digo con precauci√≥n
Celda 31: Mini Script de Limpieza de Categor√≠as
# Celda 31
# Mini script para consolidar algunas limpiezas de categor√≠as.
import numpy as np

# Reemplazar valores vac√≠os en Churn
df['Churn'] = df['Churn'].replace('', np.nan)

# Reemplazar 'No phone service' en MultipleLines
df['MultipleLines'] = df['MultipleLines'].replace('No phone service', 'No')

# Reemplazar 'No internet service' en varias columnas
cols_internet = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
                 'TechSupport', 'StreamingTV', 'StreamingMovies']
for col in cols_internet:
    df[col] = df[col].replace('No internet service', 'No')
Usa el c√≥digo con precauci√≥n
Celda 32: Verificaci√≥n Post-Mini Script
# Celda 32
# Verificaci√≥n de categor√≠as despu√©s del mini script de limpieza.
for col in df.select_dtypes(include='object'):
    print(f"{col}: {df[col].unique()}")
Usa el c√≥digo con precauci√≥n
Celda 33-34: Celdas Vac√≠as
# Celda 33, 34 (Vac√≠as)
pass # No hay c√≥digo
Usa el c√≥digo con precauci√≥n
Celda 35: Inicio Secci√≥n An√°lisis Gemini
## Analisis de Gemini
Usa el c√≥digo con precauci√≥n
Celda 36: Tratamiento de Churn Vac√≠o (Sugerido por Gemini)
# Celda 36
# Verificaci√≥n y tratamiento de Churn vac√≠o, posiblemente sugerido por Gemini.
# Verificar cu√°ntas filas tienen Churn vac√≠o
print(df[df['Churn'] == ''].shape[0]) # Si ya se reemplaz√≥ '' con NaN, esto ser√° 0.

# Opci√≥n 1: Eliminar filas con Churn vac√≠o (si son pocas y no cruciales)
df = df[df['Churn'] != ''].copy() # Si ya se reemplaz√≥ '' con NaN, esta l√≠nea no eliminar√° nada con ''. Deber√≠a ser df.dropna(subset=['Churn']).copy()

# Opci√≥n 2: Reemplazar con NaN (comentada, ya hecha en celdas anteriores)
# df['Churn'] = df['Churn'].replace('', np.nan)
Usa el c√≥digo con precauci√≥n
Celda 37: Inicio Fase de Transformaci√≥n (Revisitada)
# üîß Transformaci√≥n

Usa el c√≥digo con precauci√≥n
Celda 38: Comentario sobre Desanidar Columnas (Revisitado)
## Fase de Transformaci√≥n: Desanidando Columnas
El siguiente paso es crucial: vamos a desanidar las columnas que contienen diccionarios para que toda la informaci√≥n quede accesible y lista para el an√°lisis. Como vimos, customer, phone, internet y account son las columnas que necesitamos expandir.
Usa el c√≥digo con precauci√≥n
Celda 39: Desanidamiento Manual (Segundo Intento con Concat)
# Celda 39
# **REPETICI√ìN DEL PROCESO DE DESANIDAMIENTO Y COMBINACI√ìN**
# Carga datos originales de nuevo y realiza el aplanamiento usando pd.concat.
import pandas as pd
import requests

# Re-cargamos los datos para asegurarnos de tener el estado inicial (o el √∫ltimo que hayas guardado)
url = 'https://raw.githubusercontent.com/TAGARA-TECH/ChallengeTelecomX/main/TelecomX_Data.json'
response = requests.get(url)
data_json = response.json()
df = pd.DataFrame(data_json) # ¬°Sobrescribe 'df' con datos crudos otra vez!

print("DataFrame original (primeras 3 filas):")
print(df.head(3))
print("\n---")

# --- Desanidando la columna 'customer' ---
df_customer_expanded = df['customer'].apply(pd.Series)
print("\nColumnas expandidas de 'customer' (primeras 3 filas):")
print(df_customer_expanded.head(3))
print("\n---")

# --- Desanidando la columna 'phone' ---
df_phone_expanded = df['phone'].apply(pd.Series)
print("\nColumnas expandidas de 'phone' (primeras 3 filas):")
print(df_phone_expanded.head(3))
print("\n---")

# --- Desanidando la columna 'internet' ---
df_internet_expanded = df['internet'].apply(pd.Series)
print("\nColumnas expandidas de 'internet' (primeras 3 filas):")
print(df_internet_expanded.head(3))
print("\n---")

# --- Desanidando la columna 'account' ---
df_account_expanded = df['account'].apply(pd.Series)
print("\nColumnas expandidas de 'account' (primeras 3 filas):")
print(df_account_expanded.head(3))
print("\n---")

# --- Combinando todo en un solo DataFrame ---
# 1. Eliminamos las columnas originales que conten√≠an los diccionarios.
df = df.drop(columns=['customer', 'phone', 'internet', 'account'])

# 2. Concatenamos los DataFrames expandidos al DataFrame principal.
df = pd.concat([df, df_customer_expanded, df_phone_expanded, df_internet_expanded, df_account_expanded], axis=1)

print("\nDataFrame despu√©s de desanidar (primeras 5 filas):")
print(df.head())
print("\n---")

# Verificamos la nueva estructura y tipos de datos
print("\nDimensiones del DataFrame despu√©s de desanidar:", df.shape)
print("\nInformaci√≥n del DataFrame despu√©s de desanidar:")
df.info()
Usa el c√≥digo con precauci√≥n
Celda 40-42: Celdas Vac√≠as
# Celda 40, 41, 42 (Vac√≠as)
pass # No hay c√≥digo
Usa el c√≥digo con precauci√≥n
Celda 43: Verificaci√≥n Post-Desanidamiento
# Celda 43
# Verificaci√≥n del DataFrame despu√©s del segundo proceso de desanidamiento.
print(df.head())
print(df.info())
Usa el c√≥digo con precauci√≥n
Celda 44: Siguientes Pasos de Transformaci√≥n
### siguientes pasos:

Desanidar la columna Charges en Monthly y Total.
Convertir Monthly y Total a tipos num√©ricos y manejar los posibles valores no num√©ricos.
Tratar la columna Churn: reemplazar los valores vac√≠os con NA y eliminar las filas correspondientes.
Convertir las columnas categ√≥ricas al tipo category para optimizar el rendimiento y asegurar un manejo adecuado en el an√°lisis.
Usa el c√≥digo con precauci√≥n
Celda 45: Implementaci√≥n Completa de Limpieza y Transformaci√≥n
# Celda 45
# **Implementaci√≥n m√°s completa de la limpieza y transformaci√≥n (Similar a la l√≥gica de la funci√≥n limpiar_dataset_telecom)**
# Carga datos originales de nuevo y realiza una limpieza y transformaci√≥n integral.

import pandas as pd
import requests
import numpy as np # Necesario para pd.NA y fillna(0)

# Re-carga los datos para asegurarnos de tener el estado inicial (o el √∫ltimo que hayas guardado)
url = 'https://raw.githubusercontent.com/TAGARA-TECH/ChallengeTelecomX/main/TelecomX_Data.json'
response = requests.get(url)
data_json = response.json()
df = pd.DataFrame(data_json) # ¬°Sobrescribe 'df' con datos crudos por tercera vez!

print("DataFrame original (primeras 3 filas):")
print(df.head(3))
print("\n---")

# --- Desanidando las columnas ---
df_customer_expanded = df['customer'].apply(pd.Series)
df_phone_expanded = df['phone'].apply(pd.Series)
df_internet_expanded = df['internet'].apply(pd.Series)
df_account_expanded = df['account'].apply(pd.Series)

# --- Desanidando la columna 'Charges' dentro de 'account' ---
# Verificamos si la columna 'Charges' existe en df_account_expanded antes de intentar desanidar
if 'Charges' in df_account_expanded.columns:
    df_charges_expanded = df_account_expanded['Charges'].apply(pd.Series)
    df_account_expanded = df_account_expanded.drop(columns=['Charges']) # Eliminar 'Charges' del df_account_expanded
    print("Columna 'Charges' desanidada correctamente.")
else:
    # Si 'Charges' no est√° en df_account_expanded, creamos un DataFrame vac√≠o.
    df_charges_expanded = pd.DataFrame()
    print("Advertencia: La columna 'Charges' no se encontr√≥ en df_account_expanded para desanidar.")


# --- Combinando todo en un solo DataFrame ---
# 1. Eliminamos las columnas originales anidadas.
cols_to_drop_original = ['customer', 'phone', 'internet', 'account']
df = df.drop(columns=[col for col in cols_to_drop_original if col in df.columns]) # Eliminar solo si existen

# 2. Concatenamos los DataFrames expandidos, asegurando que no est√©n vac√≠os.
dataframes_to_concat = [df]
if not df_customer_expanded.empty: dataframes_to_concat.append(df_customer_expanded)
if not df_phone_expanded.empty: dataframes_to_concat.append(df_phone_expanded)
if not df_internet_expanded.empty: dataframes_to_concat.append(df_internet_expanded)
if not df_account_expanded.empty: dataframes_to_concat.append(df_account_expanded)
if not df_charges_expanded.empty: dataframes_to_concat.append(df_charges_expanded)

df = pd.concat(dataframes_to_concat, axis=1)


print("\nDataFrame despu√©s de desanidar (primeras 5 filas):")
print(df.head())
print("\n---")

# --- Eliminar la columna 'customerID' ya que no es necesaria para el an√°lisis ---
if 'customerID' in df.columns:
    df.drop(columns=['customerID'], inplace=True)
    print("\nColumna 'customerID' eliminada.")
else:
    print("\nLa columna 'customerID' no se encontr√≥ (ya hab√≠a sido eliminada o no se cre√≥).")


# --- 2. Convertir 'Monthly' y 'Total' a tipos num√©ricos y manejar NaNs ---
# 'errors='coerce'' convertir√° cualquier valor no num√©rico a NaN.
if 'Total' in df.columns:
    df['Total'] = pd.to_numeric(df['Total'], errors='coerce')
    df['Total'] = df['Total'].fillna(0) # Rellenar NaNs con 0
    print(f"Valores nulos en 'Total' despu√©s de rellenar con 0: {df['Total'].isna().sum()}")
else:
     print("La columna 'Total' no se encontr√≥ para convertir a num√©rico.")

if 'Monthly' in df.columns:
    df['Monthly'] = pd.to_numeric(df['Monthly'], errors='coerce')
    df['Monthly'] = df['Monthly'].fillna(0) # Rellenar NaNs con 0
    print(f"Valores nulos en 'Monthly' despu√©s de rellenar con 0: {df['Monthly'].isna().sum()}")
else:
    print("La columna 'Monthly' no se encontr√≥ para convertir a num√©rico.")


# --- 3. Tratamiento de valores en blanco en la columna 'Churn' ---
if 'Churn' in df.columns:
    print("Valores √∫nicos en 'Churn' ANTES de la limpieza:", df['Churn'].unique())
    df['Churn'] = df['Churn'].replace('', pd.NA) # Reemplazamos '' por pd.NA
    df.dropna(subset=['Churn'], inplace=True) # Eliminamos las filas donde 'Churn' es NA
    print("Valores √∫nicos en 'Churn' DESPU√âS de la limpieza:", df['Churn'].unique())
    print(f"N√∫mero de filas despu√©s de eliminar NAs en 'Churn': {len(df)}")
else:
    print("La columna 'Churn' no se encontr√≥ para limpieza.")

print("\n---")

# --- 4. Conversi√≥n de tipos de datos ---
# Lista de columnas categ√≥ricas.
categorical_cols = [
    'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
    'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
    'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',
    'PaperlessBilling', 'PaymentMethod', 'Churn'
]

# Convertimos cada columna en la lista a tipo 'category'.
for col in categorical_cols:
    if col in df.columns: # Verificamos que la columna exista
        df[col] = df[col].astype('category')
    else:
        print(f"Advertencia: La columna '{col}' no se encontr√≥ para convertir a tipo 'category'.")

# Verificaci√≥n final.
print("\nDimensiones finales del DataFrame despu√©s de todas las transformaciones:", df.shape)
print("\nInformaci√≥n final del DataFrame:")
df.info()

if 'Churn' in df.columns:
    print("\nConteo de valores de Churn (final):")
    print(df['Churn'].value_counts())
Usa el c√≥digo con precauci√≥n
Celda 46: Inicio Fase de EDA
### ¬°Ahora pasamos a la fase de An√°lisis Exploratorio de Datos (EDA)!
El EDA es donde empezamos a descubrir patrones, relaciones y anomal√≠as en los datos. Esto nos ayudar√° a entender qu√© factores podr√≠an estar influyendo en el churn de los clientes de Telecom X.

Podemos abordar el EDA de varias maneras. Te sugiero que comencemos con los siguientes pasos:

An√°lisis de la distribuci√≥n de la variable objetivo (Churn): Ver la proporci√≥n de clientes que se fueron (Yes) versus los que se quedaron (No). Esto es fundamental para entender el desequilibrio de clases, si lo hay.
An√°lisis univariado de caracter√≠sticas categ√≥ricas:
Contar la frecuencia de cada categor√≠a.
Visualizar la distribuci√≥n de cada categor√≠a (por ejemplo, con gr√°ficos de barras).
Ver c√≥mo cada categor√≠a se relaciona con la variable Churn (por ejemplo, ¬ølos clientes con cierto tipo de contrato tienen m√°s probabilidades de irse?).
An√°lisis univariado de caracter√≠sticas num√©ricas:
Obtener estad√≠sticas descriptivas (media, mediana, desviaci√≥n est√°ndar, etc.).
Visualizar la distribuci√≥n (por ejemplo, con histogramas o boxplots).
Ver c√≥mo estas variables se relacionan con Churn (por ejemplo, ¬ølos clientes con facturas mensuales m√°s altas o m√°s bajas tienen m√°s probabilidades de irse?).
Usa el c√≥digo con precauci√≥n
Celda 47: An√°lisis Exploratorio de Datos (EDA)
# Celda 47
# Inicio del An√°lisis Exploratorio de Datos (EDA).
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# NOTA IMPORTANTE: Asumimos que el DataFrame 'df' ya est√° cargado y completamente
# transformado en tu entorno, tal como lo dej√≥ la Celda 45.

print("--- An√°lisis Exploratorio de Datos (EDA) ---")

# --- 1. An√°lisis de la variable objetivo: Churn ---
print("\n--- Distribuci√≥n de la variable objetivo 'Churn' ---")
churn_counts = df['Churn'].value_counts()
print(churn_counts)
print(f"Porcentaje de Churn: {churn_counts['Yes'] / len(df) * 100:.2f}%")
print(f"Porcentaje de No-Churn: {churn_counts['No'] / len(df) * 100:.2f}%")

# Visualizaci√≥n de Churn
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Churn', palette='viridis')
plt.title('Distribuci√≥n de Clientes con Churn y Sin Churn')
plt.xlabel('Churn')
plt.ylabel('N√∫mero de Clientes')
plt.show()

# --- 2. An√°lisis de Caracter√≠sticas Categ√≥ricas seleccionadas vs. Churn ---
# Lista de columnas categ√≥ricas para analizar.
categorical_features_to_analyze = ['gender', 'Partner', 'Dependents', 'Contract']

for col in categorical_features_to_analyze:
    print(f"\n--- An√°lisis de la caracter√≠stica: '{col}' ---")

    # Frecuencia de cada categor√≠a
    print(f"Frecuencia de categor√≠as en '{col}':")
    print(df[col].value_counts())

    # Tasa de Churn por categor√≠a
    churn_rate_by_category = df.groupby(col)['Churn'].value_counts(normalize=True).unstack()

    # Manejar el caso donde una categor√≠a no tiene 'Yes' o 'No' para Churn
    if 'No' not in churn_rate_by_category.columns: churn_rate_by_category['No'] = 0
    if 'Yes' not in churn_rate_by_category.columns: churn_rate_by_category['Yes'] = 0

    churn_rate_by_category['Churn_Rate (%)'] = churn_rate_by_category['Yes'] * 100
    print(f"\nTasa de Churn por '{col}':")
    print(churn_rate_by_category[['Churn_Rate (%)']])

    # Visualizaci√≥n: Gr√°fico de barras de recuento con 'hue'
    plt.figure(figsize=(8, 5))
    sns.countplot(data=df, x=col, hue='Churn', palette='magma')
    plt.title(f'Distribuci√≥n de Churn por {col}')
    plt.xlabel(col)
    plt.ylabel('N√∫mero de Clientes')
    plt.xticks(rotation=0)
    plt.legend(title='Churn')
    plt.show()
Usa el c√≥digo con precauci√≥n
Celda 48: Verificaci√≥n de Duplicados (Repetici√≥n)
# Celda 48
# Verificaci√≥n de duplicados (Repetici√≥n).
print("Cantidad de filas duplicadas:", df.duplicated().sum())
Usa el c√≥digo con precauci√≥n
Celda 49: Eliminaci√≥n de Duplicados (Repetici√≥n)
# Celda 49
# Eliminaci√≥n de duplicados (Repetici√≥n).
df.drop_duplicates(inplace=True)
Usa el c√≥digo con precauci√≥n
Celda 50: Verificaci√≥n Post-Eliminaci√≥n de Duplicados (Repetici√≥n)
# Celda 50
# Verificaci√≥n despu√©s de eliminar duplicados (Repetici√≥n).
print("Cantidad de filas duplicadas:", df.duplicated().sum())
Usa el c√≥digo con precauci√≥n
Celda 51: Normalizaci√≥n de Categor√≠as (Repetici√≥n)
# Celda 51
# Normalizaci√≥n de categor√≠as tipo ‚ÄòNo internet service‚Äô o ‚ÄòNo phone service‚Äô (Repetici√≥n).

columns_replace_no_internet = [
    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
    'TechSupport', 'StreamingTV', 'StreamingMovies'
]
columns_replace_no_phone = ['MultipleLines']

# Reemplazo de 'No internet service' por 'No'
for col in columns_replace_no_internet:
    if col in df.columns:
        df[col] = df[col].replace({'No internet service': 'No'})

# Reemplazo de 'No phone service' por 'No'
for col in columns_replace_no_phone:
    if col in df.columns:
        df[col] = df[col].replace({'No phone service': 'No'})

print("\nCategor√≠as normalizadas: 'No internet service' y 'No phone service' reemplazadas por 'No'.")
Usa el c√≥digo con precauci√≥n
Celda 52: Normalizaci√≥n de Categor√≠as sin Warnings
# Celda 52
# Reemplazo de 'No internet service' y 'No phone service' sin warnings (Versi√≥n mejorada de Celda 51).
columns_replace_no_internet = [
    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
    'TechSupport', 'StreamingTV', 'StreamingMovies'
]
columns_replace_no_phone = ['MultipleLines']

for col in columns_replace_no_internet:
    if col in df.columns:
        df[col] = df[col].astype('object').replace({'No internet service': 'No'})
        df[col] = df[col].astype('category')

for col in columns_replace_no_phone:
    if col in df.columns:
        df[col] = df[col].astype('object').replace({'No phone service': 'No'})
        df[col] = df[col].astype('category')

print("\nCategor√≠as normalizadas sin warnings.")
Usa el c√≥digo con precauci√≥n
Celda 53: Verificaci√≥n de Categor√≠as Normalizadas
# Celda 53
# Verificar que ya no hay valores antiguos en esas columnas.
for col in columns_replace_no_internet + columns_replace_no_phone:
    if col in df.columns:
        print(f"{col} - Categor√≠as actuales: {df[col].cat.categories.tolist()}")
Usa el c√≥digo con precauci√≥n
Celda 54: Normalizaci√≥n de Formatos en Churn
# Celda 54
# Normalizaci√≥n de formatos en Churn (mapear Yes/No a True/False).
df['Churn'] = df['Churn'].map({'Yes': True, 'No': False})
Usa el c√≥digo con precauci√≥n
Celda 55: Guardado Intermedio del Dataset Limpio
# Celda 55
# Guardado intermedio del dataset limpio a CSV.
df.to_csv("TelecomX_limpio.csv", index=False)
Usa el c√≥digo con precauci√≥n
Celda 56: Definici√≥n de la Funci√≥n de Limpieza
# Celda 56
# Definici√≥n de la funci√≥n `limpiar_dataset_telecom` que encapsula el proceso ETL completo.
def limpiar_dataset_telecom(df_original):
    import pandas as pd
    import numpy as np

    # Copiamos el DataFrame original para no modificar el original
    df = df_original.copy()

    # --- Desanidar columnas ---
    df_customer = df['customer'].apply(pd.Series)
    df_phone = df['phone'].apply(pd.Series)
    df_internet = df['internet'].apply(pd.Series)
    df_account = df['account'].apply(pd.Series)

    # Desanidar 'Charges' dentro de 'account' si existe
    if 'Charges' in df_account.columns:
        df_charges = df_account['Charges'].apply(pd.Series)
        df_account.drop(columns=['Charges'], inplace=True)
    else:
        df_charges = pd.DataFrame()

    # Eliminar columnas anidadas originales
    df.drop(columns=['customer', 'phone', 'internet', 'account'], inplace=True, errors='ignore')

    # Combinar todos los DataFrames desanidados
    dataframes_combinados = [df, df_customer, df_phone, df_internet, df_account, df_charges]
    df = pd.concat([d for d in dataframes_combinados if not d.empty], axis=1)

    # Eliminar columna customerID si existe
    df.drop(columns=['customerID'], inplace=True, errors='ignore')

    # Convertir 'Total' y 'Monthly' a num√©rico
    for col in ['Total', 'Monthly']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # Limpieza de columna 'Churn'
    if 'Churn' in df.columns:
        df['Churn'] = df['Churn'].replace('', pd.NA)
        df.dropna(subset=['Churn'], inplace=True)

    # Columnas categ√≥ricas
    cat_cols = [
        'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
        'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
        'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',
        'PaperlessBilling', 'PaymentMethod', 'Churn'
    ]
    for col in cat_cols:
        if col in df.columns:
            df[col] = df[col].astype('category')

    # Normalizar 'No internet service' y 'No phone service'
    columnas_no_internet = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']
    columnas_no_phone = ['MultipleLines']

    for col in columnas_no_internet:
        if col in df.
